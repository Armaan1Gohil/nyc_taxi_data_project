{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5fee2b7-2e20-4971-ab1c-0398ad9f4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "986e8379-26b8-473f-881d-24ddff425678",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = sys.argv[1]\n",
    "month = sys.argv[2]\n",
    "catalogue = 'nessie'\n",
    "namespace = 'nyc_project_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca077e71-5b78-48a1-ba2b-02b074b8e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = 's3a://nyc-project/raw-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff620977-e0a2-4e99-bf5f-5798da462433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('data_transformation') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d08222ee-c4fd-4782-aa30-0304f749a679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a226243b-6d92-4e9e-9212-c3136a5c5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_schema = types.StructType([\n",
    "    types.StructField('VendorID', types.IntegerType(), True), \n",
    "    types.StructField('tpep_pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('tpep_dropoff_datetime', types.TimestampType(), True), \n",
    "    types.StructField('passenger_count', types.IntegerType(), True), \n",
    "    types.StructField('trip_distance', types.FloatType(), True), \n",
    "    types.StructField('RatecodeID', types.IntegerType(), True), \n",
    "    types.StructField('store_and_fwd_flag', types.StringType(), True), \n",
    "    types.StructField('PULocationID', types.IntegerType(), True), \n",
    "    types.StructField('DOLocationID', types.IntegerType(), True), \n",
    "    types.StructField('payment_type', types.IntegerType(), True), \n",
    "    types.StructField('fare_amount', types.FloatType(), True), \n",
    "    types.StructField('extra', types.FloatType(), True), \n",
    "    types.StructField('mta_tax', types.FloatType(), True), \n",
    "    types.StructField('tip_amount', types.FloatType(), True), \n",
    "    types.StructField('tolls_amount', types.FloatType(), True), \n",
    "    types.StructField('improvement_surcharge', types.FloatType(), True), \n",
    "    types.StructField('total_amount', types.FloatType(), True), \n",
    "    types.StructField('congestion_surcharge', types.FloatType(), True), \n",
    "    types.StructField('airport_fee', types.IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "481f32e2-722e-4f62-a49b-9afb884f3a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 11:31:27 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option('headers', True).parquet(f'{s3_path}/2019/01/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "056b1c29-58e3-4173-80cb-a2f891013539",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_schema = df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de8becd5-bf83-4106-bb2e-f697aa549c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for old_field, new_field in zip(old_schema.fields, new_schema.fields):\n",
    "    df = df.withColumn(new_field.name, col(old_field.name).cast(new_field.dataType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef0183e8-6fdf-46b7-94c6-debcd6fd3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed('VendorID', 'vendor_id') \\\n",
    "    .withColumnRenamed('RatecodeID', 'ratecode_id') \\\n",
    "    .withColumnRenamed('payment_type', 'payment_type_id') \\\n",
    "    .withColumnRenamed('tpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('tpep_dropoff_datetime', 'dropoff_datetime') \\\n",
    "    .withColumnRenamed('PULocationID', 'pickup_location_id') \\\n",
    "    .withColumnRenamed('DOLocationID', 'dropoff_location_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00275fbd-a65d-459c-b975-1e1bbdeb77fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.filter((col('fare_amount') > 0) \\\n",
    "               & (col('trip_distance') > 0) \\\n",
    "               & (col('extra') > 0))\n",
    "\n",
    "df = df.filter((col('ratecode_id') <= 6))\n",
    "\n",
    "df = df.withColumn('congestion_surcharge', F.when(col('congestion_surcharge').isNull(), 0).otherwise(col('congestion_surcharge')))\n",
    "df = df.withColumn('airport_fee', F.when(col('airport_fee').isNull(), 0).otherwise(col('airport_fee')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b89f317-1f19-47f3-9098-69bfed75cb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 11:31:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/13 11:31:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/13 11:31:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "24/12/13 11:31:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "window_spec = Window.orderBy('passenger_count')\n",
    "\n",
    "df_rn = df.select(['passenger_count']).withColumn('rn', F.row_number().over(window_spec))\n",
    "total_rows = df.count()\n",
    "                                                         \n",
    "if total_rows % 2 == 0:\n",
    "    lower_mid = total_rows // 2\n",
    "    upper_mid = lower_mid + 1\n",
    "else:\n",
    "    lower_mid = total_rows // 2 + 1\n",
    "    upper_mid = lower_mid\n",
    "\n",
    "median_df = df_rn.filter((col('rn') == lower_mid) | (col('rn') == upper_mid))\n",
    "\n",
    "median_value = median_df.agg(F.avg(col('passenger_count'))).collect()[0][0]\n",
    "\n",
    "df = df.withColumn('passenger_count', F.when(col('passenger_count') == 0, median_value).otherwise(col('passenger_count')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d686f27e-c657-462e-ac2c-6eceef3ca5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_id(date_column):\n",
    "    year = F.year(date_column)\n",
    "    month = F.lpad(F.month(date_column).cast(\"string\"), 2, \"0\")\n",
    "    day = F.lpad(F.dayofmonth(date_column).cast(\"string\"), 2, \"0\")\n",
    "    hour = F.lpad(F.hour(date_column).cast(\"string\"), 2, \"0\")\n",
    "    minute = F.lpad(F.minute(date_column).cast(\"string\"), 2, \"0\")\n",
    "    second = F.lpad(F.second(date_column).cast(\"string\"), 2, \"0\")\n",
    "    index = F.concat(year, month, day, hour, minute, second)\n",
    "    return index.cast(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "395859b3-d247-4aac-8de8-c8123540e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_datetime_dim = df.select(['pickup_datetime']) \\\n",
    "    .distinct() \\\n",
    "    .withColumn('pickup_datetime_id', index_id(col('pickup_datetime'))) \\\n",
    "    .withColumn('pickup_hour', F.hour(col('pickup_datetime'))) \\\n",
    "    .withColumn('pickup_day', F.dayofmonth(col('pickup_datetime'))) \\\n",
    "    .withColumn('pickup_month', F.month(col('pickup_datetime'))) \\\n",
    "    .withColumn('pickup_year', F.year(col('pickup_datetime'))) \\\n",
    "    .withColumn('pickup_weekday', F.date_format(col('pickup_datetime'), 'EEEE'))\n",
    "\n",
    "pickup_datetime_dim = pickup_datetime_dim.select(\n",
    "    'pickup_datetime_id',\n",
    "    'pickup_datetime',\n",
    "    'pickup_hour',\n",
    "    'pickup_day',\n",
    "    'pickup_month',\n",
    "    'pickup_year',\n",
    "    'pickup_weekday'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16721413-43fe-448d-87ad-58de5d35d296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"CREATE NAMESPACE IF NOT EXISTS {catalogue}.{namespace}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8dec25df-cb31-4657-b4d5-076a3f0f9e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_name = []\n",
    "pickup_datetime_schema = pickup_datetime_dim.schema\n",
    "for field in pickup_datetime_schema.fields:\n",
    "    columns_name.append(f'{field.name} {field.dataType.simpleString().upper()}')\n",
    "columns_sql = \", \".join(columns_name)\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {catalogue}.{namespace}.pickup_datetime_table (\n",
    "    {columns_sql}\n",
    "    )\n",
    "    USING iceberg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0efd0fe0-9ef8-4442-af12-0707aff46476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pickup_datetime_dim.writeTo(f'{catalogue}.{namespace}.pickup_datetime_table').createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0484d166-7561-4c65-8333-1c661841e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropoff_datetime_dim = df.select(['dropoff_datetime']) \\\n",
    "    .distinct() \\\n",
    "    .withColumn('dropoff_datetime_id', index_id(col('dropoff_datetime'))) \\\n",
    "    .withColumn('dropoff_hour', F.hour(col('dropoff_datetime'))) \\\n",
    "    .withColumn('dropoff_day', F.dayofmonth(col('dropoff_datetime'))) \\\n",
    "    .withColumn('dropoff_month', F.month(col('dropoff_datetime'))) \\\n",
    "    .withColumn('dropoff_year', F.year(col('dropoff_datetime'))) \\\n",
    "    .withColumn('dropoff_weekday', F.date_format(col('dropoff_datetime'), 'EEEE'))\n",
    "\n",
    "dropoff_datetime_dim = dropoff_datetime_dim.select(\n",
    "    'dropoff_datetime_id',\n",
    "    'dropoff_datetime',\n",
    "    'dropoff_hour',\n",
    "    'dropoff_day',\n",
    "    'dropoff_month',\n",
    "    'dropoff_year',\n",
    "    'dropoff_weekday'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9b464a3-68aa-49d7-9df4-d6a5ac140a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_name = []\n",
    "dropoff_datetime_schema = dropoff_datetime_dim.schema\n",
    "for field in dropoff_datetime_schema.fields:\n",
    "    columns_name.append(f'{field.name} {field.dataType.simpleString().upper()}')\n",
    "columns_sql = \", \".join(columns_name)\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {catalogue}.{namespace}.dropoff_datetime_table (\n",
    "    {columns_sql}\n",
    "    )\n",
    "    USING iceberg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3a7df09-8ead-4867-a7b3-28a1538338f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dropoff_datetime_dim.writeTo(f'{catalogue}.{namespace}.dropoff_datetime_table').createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04e810f4-0b1d-4a7f-a120-22dda76f64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('dropoff_datetime_id', index_id(col('dropoff_datetime'))) \\\n",
    "    .withColumn('pickup_datetime_id', index_id(col('pickup_datetime')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43c66ecc-8eb5-4eb1-a67e-c7b09b5b2a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(['vendor_id',\n",
    " 'pickup_datetime_id',\n",
    " 'dropoff_datetime_id',\n",
    " 'pickup_location_id',\n",
    " 'dropoff_location_id',\n",
    " 'ratecode_id',\n",
    " 'passenger_count',\n",
    " 'trip_distance',\n",
    " 'payment_type_id',\n",
    " 'store_and_fwd_flag',\n",
    " 'fare_amount',\n",
    " 'extra',\n",
    " 'mta_tax',\n",
    " 'tip_amount',\n",
    " 'tolls_amount',\n",
    " 'improvement_surcharge',\n",
    " 'congestion_surcharge',\n",
    " 'airport_fee',\n",
    " 'total_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "659e9fd1-80ff-4912-a054-f5e1f8ea839d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_name = []\n",
    "df_schema = df.schema\n",
    "for field in df_schema.fields:\n",
    "    columns_name.append(f'{field.name} {field.dataType.simpleString().upper()}')\n",
    "columns_sql = \", \".join(columns_name)\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {catalogue}.{namespace}.fact_table (\n",
    "    {columns_sql}\n",
    "    )\n",
    "    USING iceberg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "115132b4-0e9f-4780-8f70-b7a994fef492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.writeTo(f'{catalogue}.{namespace}.fact_table').createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52889f4d-ac53-4acf-8085-c2e1a9486d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      catalog|\n",
      "+-------------+\n",
      "|       nessie|\n",
      "|spark_catalog|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW CATALOGS\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eedde598-fe15-41e6-8554-cd9f9dfc6542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|     namespace|\n",
      "+--------------+\n",
      "|nyc_project_db|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW NAMESPACES IN nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8054f9ba-791a-4c7c-aeb6-e9a0d27fb6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-----------+\n",
      "|     namespace|           tableName|isTemporary|\n",
      "+--------------+--------------------+-----------+\n",
      "|nyc_project_db|dropoff_datetime_...|      false|\n",
      "|nyc_project_db|          fact_table|      false|\n",
      "|nyc_project_db|pickup_datetime_t...|      false|\n",
      "+--------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES IN nessie.nyc_project_db\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bdc726e-6702-498f-86d9-2fb06ddb1d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-------------------+------------------+-------------------+-----------+---------------+-------------+---------------+------------------+-----------+-----+-------+----------+------------+---------------------+--------------------+-----------+------------+\n",
      "|vendor_id|pickup_datetime_id|dropoff_datetime_id|pickup_location_id|dropoff_location_id|ratecode_id|passenger_count|trip_distance|payment_type_id|store_and_fwd_flag|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|congestion_surcharge|airport_fee|total_amount|\n",
      "+---------+------------------+-------------------+------------------+-------------------+-----------+---------------+-------------+---------------+------------------+-----------+-----+-------+----------+------------+---------------------+--------------------+-----------+------------+\n",
      "|        1|              null|               null|               151|                239|          1|            1.0|          1.5|              1|                 N|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|                 0.0|          0|        9.95|\n",
      "|        1|              null|               null|               239|                246|          1|            1.0|          2.6|              1|                 N|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|                 0.0|          0|        16.3|\n",
      "+---------+------------------+-------------------+------------------+-------------------+-----------+---------------+-------------+---------------+------------------+-----------+-----+-------+----------+------------+---------------------+--------------------+-----------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM nessie.nyc_project_db.fact_table\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71eb2d44-55d7-4544-a6b2-dc436deded46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      catalog|\n",
      "+-------------+\n",
      "|       nessie|\n",
      "|spark_catalog|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW CATALOGS\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f43525d-3a99-442b-ba2b-e782d2bf12cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"REFRESH TABLE nessie.nyc_project_db.fact_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a1434-c1cc-4bfc-ba05-e214db6fcbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
